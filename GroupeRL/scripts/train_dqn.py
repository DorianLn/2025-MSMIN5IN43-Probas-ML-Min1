"""
Entra√Ænement d'un agent DQN sur Doom (VizDoom) - Sc√©nario Custom
Utilise le WAD Ultimate Doom fourni
"""

import os
import gymnasium
from gymnasium.envs.registration import register
from stable_baselines3 import DQN

# Cr√©er le dossier models s'il n'existe pas
os.makedirs("models", exist_ok=True)

print("=" * 60)
print("üöÄ Entra√Ænement DQN sur Doom (VizDoom)")
print("=" * 60)

# V√©rifier si VizDoom est install√©
try:
    import vizdoom
    print("‚úÖ VizDoom d√©tect√©")
except ImportError:
    print("‚ùå VizDoom n'est pas install√©. Installez-le avec : pip install vizdoom")
    print("   Note: N√©cessite Python 3.11 ou ant√©rieur pour pygame.")
    exit(1)

# Copier le WAD si n√©cessaire (assumer qu'il est dans games/DOOM.WAD)
script_dir = os.path.dirname(os.path.abspath(__file__))
wad_path = os.path.join(script_dir, "../../games/DOOM.WAD")
wad_path = os.path.abspath(wad_path)
if not os.path.exists(wad_path):
    print(f"‚ùå WAD non trouv√© √† {wad_path}")
    print("   Placez DOOM.WAD dans le dossier games/")
    exit(1)

print(f"‚úÖ WAD trouv√© : {wad_path}")

# Enregistrer un environnement personnalis√© VizDoom
register(
    id='VizdoomBasicCustom-v0',
    entry_point='vizdoom.gymnasium_wrapper.gymnasium_env_defns:VizdoomScenarioEnv',
    kwargs={'scenario_file': os.path.join(script_dir, 'basic_custom.cfg')}
)

# Cr√©er l'environnement
# render_mode=None est beaucoup plus rapide pour l'entra√Ænement (pas d'affichage fen√™tre)
env = gymnasium.make('VizdoomBasicCustom-v0', render_mode=None)
print(f"‚úÖ Environnement cr√©√© : VizdoomBasicCustom-v0")
print(f"   - Espace d'observation : {env.observation_space}")
print(f"   - Espace d'action : {env.action_space}")

# Cr√©er le mod√®le DQN avec MultiInputPolicy pour les dict observations
model = DQN(
    "MultiInputPolicy",  # Utilise MultiInputPolicy pour traiter les dict observations
    env,
    learning_rate=1e-4,  # Plus petit pour stabilit√©
    buffer_size=100000,   # Augment√© pour l'exploration
    learning_starts=5000, # Laisser l'agent explorer avant d'apprendre
    batch_size=2048,      # Augment√© pour 8Go VRAM
    target_update_interval=1000,
    verbose=1,
    device="cuda"  # Utilise GPU NVIDIA
)

print(f"\n‚úÖ Mod√®le DQN cr√©√© avec les hyperparam√®tres")
print(f"   - Policy : MultiInputPolicy (pour dict observations)")
print(f"   - Learning rate : 1e-4")
print(f"   - Buffer size : 100000")
print(f"   - Learning starts : 5000")
print(f"   - Target update interval : 1000")

# Entra√Æner le mod√®le
print(f"\n‚è≥ Entra√Ænement en cours... (10,000 timesteps)")
print(f"   Doom est complexe, cela peut prendre du temps...")
print("-" * 60)

model.learn(total_timesteps=10000)

# Sauvegarder le mod√®le
model.save("models/dqn_doom_custom")
print("-" * 60)
print(f"\n‚úÖ Entra√Ænement DQN sur Doom termin√© avec succ√®s !")
print(f"   Mod√®le sauvegard√© : models/dqn_doom_custom.zip")

env.close()
