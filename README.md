ğŸ“° DÃ©tection de Fake News par NLP AvancÃ© et Transformers
ğŸ“Œ PrÃ©sentation du projet

Ce projet sâ€™inscrit dans le cadre du module de NLP avancÃ© pour le traitement de bases de donnÃ©es.
Lâ€™objectif est de concevoir un systÃ¨me intelligent de dÃ©tection de fake news, basÃ© sur des modÃ¨les Transformers prÃ©-entraÃ®nÃ©s et fine-tunÃ©s, capables de traiter des articles de presse en anglais et en franÃ§ais.

Le projet est rÃ©alisÃ© en groupe et combine :

des techniques avancÃ©es de Traitement Automatique du Langage Naturel (TALN),

lâ€™exploitation de datasets et modÃ¨les via Hugging Face,

et le dÃ©veloppement dâ€™une interface utilisateur pour une utilisation concrÃ¨te.

ğŸ‘¥ Membres du groupe

Lamyae TALA
Safe BERRICHI
Pauline GOFFINET

ğŸ¯ Objectifs du projet

DÃ©tecter automatiquement si une information est vraie ou fausse

Appliquer des techniques de NLP avancÃ© sur de grandes bases de donnÃ©es textuelles

Fine-tuner et comparer plusieurs modÃ¨les Transformers

GÃ©rer le multilinguisme (anglais / franÃ§ais)

Mettre en place une interface interactive de vÃ©rification des news

ğŸ§  ModÃ¨les utilisÃ©s
ğŸ”¹ DonnÃ©es en anglais

Deux modÃ¨les Transformers ont Ã©tÃ© fine-tunÃ©s pour la dÃ©tection de fake news en anglais :

BERT (bert-base-uncased)

RoBERTa (roberta-base)

Ces modÃ¨les permettent une comparaison des performances sur les donnÃ©es anglophones.

ğŸ”¹ DonnÃ©es en franÃ§ais

Pour les articles en franÃ§ais, nous avons utilisÃ© :

CamemBERT (camembert-base)

CamemBERT est un modÃ¨le spÃ©cifiquement entraÃ®nÃ© pour la langue franÃ§aise, ce qui le rend particuliÃ¨rement adaptÃ© Ã  la dÃ©tection de fake news en franÃ§ais.

ğŸ—„ï¸ DonnÃ©es & Stockage des modÃ¨les

Les datasets sont chargÃ©s depuis Hugging Face Datasets

Les modÃ¨les fine-tunÃ©s sont :

sauvegardÃ©s localement,

puis stockÃ©s et versionnÃ©s sur Hugging Face Hub pour faciliter le partage, la rÃ©utilisation et la reproductibilitÃ©

ğŸ–¥ï¸ Interface utilisateur

Une interface interactive permet Ã  lâ€™utilisateur de vÃ©rifier une news en quelques clics.

ğŸ›ï¸ FonctionnalitÃ©s de lâ€™interface

Lâ€™utilisateur peut :

saisir le texte dâ€™une news,

choisir le modÃ¨le de vÃ©rification via trois boutons :

Bouton	Langue	ModÃ¨le
ğŸ‡«ğŸ‡· CamemBERT	FranÃ§ais	CamemBERT
ğŸ‡¬ğŸ‡§ BERT	Anglais	BERT
ğŸ‡¬ğŸ‡§ RoBERTa	Anglais	RoBERTa

Lâ€™interface retourne :

la prÃ©diction (Fake / Real),

un score de confiance associÃ©.

ğŸ—‚ï¸ Structure du projet
FakeNews-Detection/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ notebook_1_BERT.ipynb
â”‚   â”œâ”€â”€ notebook_2_RoBERTa.ipynb
â”‚   â””â”€â”€ notebook_3_CamemBERT.ipynb
â”‚
â”œâ”€â”€ interface/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ datasets (Hugging Face)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ bert/
â”‚   â”œâ”€â”€ roberta/
â”‚   â””â”€â”€ camembert/
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ metrics_et_evaluations/
â”‚
â””â”€â”€ README.md

âš™ï¸ Environnement technique

Langage : Python

Frameworks & bibliothÃ¨ques :

PyTorch

Hugging Face Transformers & Datasets

Scikit-learn

AccÃ©lÃ©ration matÃ©rielle :

EntraÃ®nement sur GPU (CUDA)

ğŸ§ª MÃ©thodologie

Chargement des donnÃ©es depuis Hugging Face

Nettoyage et prÃ©traitement professionnel des textes

Tokenisation adaptÃ©e Ã  chaque modÃ¨le

Fine-tuning des modÃ¨les Transformers

Ã‰valuation Ã  lâ€™aide de mÃ©triques standard

IntÃ©gration des modÃ¨les dans une interface utilisateur

ğŸ“Š Ã‰valuation

Les modÃ¨les sont Ã©valuÃ©s Ã  lâ€™aide de :

Accuracy

Precision

Recall

F1-score

Matrice de confusion

Une analyse comparative est rÃ©alisÃ©e entre BERT et RoBERTa pour les donnÃ©es anglaises, et CamemBERT pour les donnÃ©es franÃ§aises.

ğŸš€ Perspectives dâ€™amÃ©lioration

Ajout dâ€™autres langues

DÃ©ploiement de lâ€™application en ligne

AmÃ©lioration de lâ€™explicabilitÃ© des prÃ©dictions

IntÃ©gration de nouvelles sources de donnÃ©es