# ðŸ“° DÃ©tection de Fake News par NLP AvancÃ© & Transformers

## ðŸ“Œ PrÃ©sentation du projet
Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du **module de NLP avancÃ©**.  
Lâ€™objectif principal est de concevoir un **systÃ¨me intelligent de dÃ©tection de Fake News**, capable de distinguer des articles **vrais** et **faux** en **anglais** et en **franÃ§ais**, en sâ€™appuyant sur des **modÃ¨les Transformers de lâ€™Ã©tat de lâ€™art**.

Une attention particuliÃ¨re a Ã©tÃ© portÃ©e Ã  la **rÃ©silience des modÃ¨les face Ã  la dÃ©sinformation sophistiquÃ©e**, notamment les contenus complotistes bien rÃ©digÃ©s, via des **stratÃ©gies avancÃ©es de calibration et de pondÃ©ration des erreurs**.

---

## ðŸ‘¥ Membres du groupe
- **Nom PrÃ©nom**
- **Nom PrÃ©nom**
- **Nom PrÃ©nom**

*(Ã  complÃ©ter)*

---

## ðŸŽ¯ Objectifs techniques
- **Multilinguisme**  
  Fine-tuning de modÃ¨les spÃ©cifiques pour lâ€™anglais et le franÃ§ais.

- **Data Augmentation**  
  Utilisation de la **Back-Translation (FR â†” EN)** pour enrichir et Ã©quilibrer les jeux de donnÃ©es dâ€™entraÃ®nement.

- **Optimisation de la prÃ©cision**  
  ImplÃ©mentation dâ€™une **fonction de perte pondÃ©rÃ©e (Weighted Cross-Entropy)** afin de pÃ©naliser davantage les faux nÃ©gatifs.

- **Calibration de lâ€™infÃ©rence**  
  Mise en place dâ€™un **seuil de suspicion personnalisÃ©** pour dÃ©tecter des signaux faibles de dÃ©sinformation.

---

## ðŸ§  ModÃ¨les & stratÃ©gies

### ðŸ”¹ ModÃ¨les pour lâ€™anglais
- **BERT** (`bert-base-uncased`)
- **RoBERTa** (`roberta-base`)  
  â†’ Meilleure comprÃ©hension contextuelle et robustesse linguistique.

### ðŸ”¹ ModÃ¨le pour le franÃ§ais
- **CamemBERT** (`camembert-base`)  
  â†’ Fine-tuning avec **rÃ©gularisation stricte (Weight Decay)** afin de limiter le biais stylistique et le sur-apprentissage.

---

## ðŸ§ª MÃ©thodologie avancÃ©e
Pour faire face aux **Fake News trÃ¨s bien rÃ©digÃ©es**, nous avons mis en Å“uvre les techniques suivantes :

- **Back-Translation**  
  Traduction automatique via *Helsinki-NLP* pour enrichir la classe minoritaire.

- **Weighted Trainer**  
  PondÃ©ration des classes :
  - VRAI : **1.0**
  - FAKE : **3.0**  
  afin de rendre le modÃ¨le plus vigilant face Ã  la dÃ©sinformation.

- **Ultra-Suspicious Threshold**  
  Ajustement du seuil de dÃ©cision lors de lâ€™infÃ©rence :  
  un article est signalÃ© comme **suspect** dÃ¨s que la confiance en la classe *VRAI* descend sous **99.99%**.

---

## ðŸ–¥ï¸ Interface utilisateur
Une **interface interactive** permet Ã  lâ€™utilisateur de saisir un texte et dâ€™obtenir un diagnostic immÃ©diat selon le modÃ¨le choisi.

| Bouton | Langue | ModÃ¨le |
|------|------|------|
| ðŸ‡«ðŸ‡· CamemBERT | FranÃ§ais | CamemBERT v2 (calibrÃ©) |
| ðŸ‡¬ðŸ‡§ BERT | Anglais | BERT-base |
| ðŸ‡¬ðŸ‡§ RoBERTa | Anglais | RoBERTa-base |

---

## ðŸ—‚ï¸ Structure du projet
```text
.
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EN_Fakenews_Bert.ipynb      # Pipeline anglais - BERT
â”‚   â”œâ”€â”€ EN_fakenews_RoBERTa.ipynb   # Pipeline anglais - RoBERTa
â”‚   â””â”€â”€ FR_Fake.ipynb               # Pipeline franÃ§ais (augmentation + calibration)
â”œâ”€â”€ interface/
â”‚   â””â”€â”€ app.py                     # Application Streamlit / Gradio
â”œâ”€â”€ .gitignore                     # Exclusion des modÃ¨les > 100 Mo
â””â”€â”€ README.md
